{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Outcome')\n",
    "X = df[properties]\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(input_shape=(8,)),\n",
    "                            keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "                            keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "                            keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 1.5443 - accuracy: 0.6058\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.8774 - accuracy: 0.6426\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.9210 - accuracy: 0.6258: 0s - loss: 0.9566 - accura\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.7964 - accuracy: 0.6457: 0s - loss: 0.8135 - accuracy\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.7728 - accuracy: 0.6258\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.7652 - accuracy: 0.6334\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.7472 - accuracy: 0.6626\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.7226 - accuracy: 0.6595\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 980us/step - loss: 0.7272 - accuracy: 0.6319\n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 968us/step - loss: 0.6759 - accuracy: 0.6764\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 960us/step - loss: 0.6733 - accuracy: 0.6534\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 965us/step - loss: 0.6834 - accuracy: 0.6580\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 957us/step - loss: 0.6533 - accuracy: 0.6656\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 953us/step - loss: 0.6755 - accuracy: 0.6610\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 918us/step - loss: 0.6471 - accuracy: 0.6672\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 1s 943us/step - loss: 0.6350 - accuracy: 0.6779\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 962us/step - loss: 0.6296 - accuracy: 0.6718\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6183 - accuracy: 0.6779\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.6825\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 924us/step - loss: 0.6426 - accuracy: 0.6963\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 941us/step - loss: 0.6308 - accuracy: 0.6902\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 949us/step - loss: 0.6082 - accuracy: 0.7086\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 962us/step - loss: 0.6013 - accuracy: 0.7147\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 926us/step - loss: 0.6129 - accuracy: 0.7163\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 1s 926us/step - loss: 0.6052 - accuracy: 0.7055\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7069\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 822us/step - loss: 0.5769 - accuracy: 0.6871\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 811us/step - loss: 0.5713 - accuracy: 0.6887\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 825us/step - loss: 0.5662 - accuracy: 0.6979\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 808us/step - loss: 0.5615 - accuracy: 0.7055\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 810us/step - loss: 0.5574 - accuracy: 0.7086\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 806us/step - loss: 0.5539 - accuracy: 0.7117\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 877us/step - loss: 0.5504 - accuracy: 0.7101\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 832us/step - loss: 0.5475 - accuracy: 0.71170s - loss: 0.5351 - accuracy: \n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 813us/step - loss: 0.5447 - accuracy: 0.7147\n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 830us/step - loss: 0.5424 - accuracy: 0.7178\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 867us/step - loss: 0.5405 - accuracy: 0.72240s - loss: 0.5241 - accuracy: \n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 819us/step - loss: 0.5384 - accuracy: 0.7224\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 815us/step - loss: 0.5366 - accuracy: 0.7239\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 819us/step - loss: 0.5349 - accuracy: 0.7239\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 812us/step - loss: 0.5334 - accuracy: 0.7270\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 1s 818us/step - loss: 0.5322 - accuracy: 0.7224\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 812us/step - loss: 0.5311 - accuracy: 0.7224\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 808us/step - loss: 0.5302 - accuracy: 0.7239\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 796us/step - loss: 0.5295 - accuracy: 0.7224\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 839us/step - loss: 0.5287 - accuracy: 0.7255\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 820us/step - loss: 0.5281 - accuracy: 0.7255\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 804us/step - loss: 0.5275 - accuracy: 0.7239\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 840us/step - loss: 0.5270 - accuracy: 0.7255\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 817us/step - loss: 0.5265 - accuracy: 0.7270\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 1s 821us/step - loss: 0.5261 - accuracy: 0.7270\n",
      "4/4 [==============================] - 0s 958us/step - loss: 0.5387 - accuracy: 0.6897\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 799us/step - loss: 0.5299 - accuracy: 0.7423\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 817us/step - loss: 0.5241 - accuracy: 0.7439\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 822us/step - loss: 0.5223 - accuracy: 0.7469\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 864us/step - loss: 0.5215 - accuracy: 0.7546\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 965us/step - loss: 0.5209 - accuracy: 0.74850s - loss: 0.5216 - accura\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 857us/step - loss: 0.5205 - accuracy: 0.7515\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5206 - accuracy: 0.7546\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5200 - accuracy: 0.7515\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.7485: 0s - loss: 0.5091 \n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5194 - accuracy: 0.7592: 0s - l\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5193 - accuracy: 0.7439\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5193 - accuracy: 0.7500: 0s - loss: 0.5283 - accuracy: \n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5191 - accuracy: 0.7531\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 882us/step - loss: 0.5189 - accuracy: 0.7577\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 861us/step - loss: 0.5187 - accuracy: 0.7561\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5184 - accuracy: 0.7500: 0s\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7500\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7500\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 3s 5ms/step - loss: 0.5183 - accuracy: 0.7531\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 3s 4ms/step - loss: 0.5181 - accuracy: 0.7500\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7561\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 967us/step - loss: 0.5180 - accuracy: 0.7531\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7531\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5177 - accuracy: 0.7531\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 1s 917us/step - loss: 0.5178 - accuracy: 0.7485\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7155\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5868 - accuracy: 0.7071\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6023 - accuracy: 0.7132\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.7163\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5977 - accuracy: 0.7071\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5667 - accuracy: 0.7209\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5900 - accuracy: 0.7101\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5979 - accuracy: 0.7086\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5779 - accuracy: 0.7101\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5549 - accuracy: 0.7224\n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7239\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7239\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5572 - accuracy: 0.7255\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7469\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7270\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5638 - accuracy: 0.7362: 0s - loss: 0.5864 - accu\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7316\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7331\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7362\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7408\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7331\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7239\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7454\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 985us/step - loss: 0.5200 - accuracy: 0.7469\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.5292 - accuracy: 0.7301: 0s - loss: 0.5356 - accuracy: \n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 1s 991us/step - loss: 0.5244 - accuracy: 0.74080s - loss: 0.5275 - accura\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7500\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 860us/step - loss: 0.5011 - accuracy: 0.7423\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 847us/step - loss: 0.4907 - accuracy: 0.75150s - loss: 0.5106 - accu\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 880us/step - loss: 0.4868 - accuracy: 0.7531\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 878us/step - loss: 0.4917 - accuracy: 0.75000s - loss: 0.4919 - accuracy: \n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 841us/step - loss: 0.4883 - accuracy: 0.7408\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 860us/step - loss: 0.4852 - accuracy: 0.7423\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 899us/step - loss: 0.4867 - accuracy: 0.7531\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 876us/step - loss: 0.4836 - accuracy: 0.7592\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 872us/step - loss: 0.4835 - accuracy: 0.7577\n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 895us/step - loss: 0.4841 - accuracy: 0.7454\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 880us/step - loss: 0.4825 - accuracy: 0.75000s - loss: 0.4666 - accuracy: \n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 891us/step - loss: 0.4819 - accuracy: 0.7515\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.4790 - accuracy: 0.7546\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 887us/step - loss: 0.4784 - accuracy: 0.7638\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 885us/step - loss: 0.4803 - accuracy: 0.7607\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 1s 876us/step - loss: 0.4771 - accuracy: 0.7592\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 881us/step - loss: 0.4795 - accuracy: 0.7454\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 859us/step - loss: 0.4760 - accuracy: 0.7561\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 855us/step - loss: 0.4756 - accuracy: 0.7699\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 870us/step - loss: 0.4760 - accuracy: 0.7592\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 859us/step - loss: 0.4777 - accuracy: 0.7546\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 898us/step - loss: 0.4752 - accuracy: 0.7531\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 874us/step - loss: 0.4732 - accuracy: 0.7699\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 913us/step - loss: 0.4731 - accuracy: 0.75770s - loss: 0.4542 - accu\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 1s 885us/step - loss: 0.4763 - accuracy: 0.7592\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7586\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 867us/step - loss: 0.7035 - accuracy: 0.5199\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 1s 893us/step - loss: 0.6413 - accuracy: 0.6794\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 863us/step - loss: 0.6338 - accuracy: 0.6933\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 823us/step - loss: 0.6312 - accuracy: 0.6948\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 834us/step - loss: 0.6301 - accuracy: 0.6871\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 839us/step - loss: 0.6294 - accuracy: 0.6840\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 853us/step - loss: 0.6288 - accuracy: 0.6840\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 880us/step - loss: 0.6284 - accuracy: 0.6825\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 863us/step - loss: 0.6280 - accuracy: 0.68400s - loss: 0.6294 - accuracy: \n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 865us/step - loss: 0.6276 - accuracy: 0.6840\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 869us/step - loss: 0.6273 - accuracy: 0.6871\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 844us/step - loss: 0.6270 - accuracy: 0.6856\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 842us/step - loss: 0.6268 - accuracy: 0.6856\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 862us/step - loss: 0.6265 - accuracy: 0.6840\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 861us/step - loss: 0.6263 - accuracy: 0.6825\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 1s 872us/step - loss: 0.6261 - accuracy: 0.6840\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 884us/step - loss: 0.6260 - accuracy: 0.6825\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6258 - accuracy: 0.6810\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6256 - accuracy: 0.6810\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6254 - accuracy: 0.6840\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6253 - accuracy: 0.6810: 0s - loss: 0.6306 \n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6251 - accuracy: 0.6825\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.6250 - accuracy: 0.6840\n",
      "Epoch 24/25\n",
      "544/652 [========================>.....] - ETA: 0s - loss: 0.6289 - accuracy: 0.6746 ETA: 0s - loss: 0.6314 - accura"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c55131925fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2174\u001b[0m         \u001b[0moutputs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m     ret = nest.pack_sequence_as(self._func_graph.structured_outputs,\n\u001b[0m\u001b[1;32m   2177\u001b[0m                                 outputs_list, expand_composites=True)\n\u001b[1;32m   2178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    497\u001b[0m                       sequence_fn=None):\n\u001b[1;32m    498\u001b[0m   \u001b[0;34m\"\"\"Implements sequence packing, with the option to alter the structure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m   \u001b[0mis_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_sequence_or_composite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexpand_composites\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt_name = [\"nadam\", \"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"ftrl\"]\n",
    "model_acc = []\n",
    "temp_max = 0\n",
    "max_index = 0\n",
    "index = 0\n",
    "for name in opt_name:\n",
    "    model.compile(optimizer=name,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=25, batch_size=1)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    if temp_max < test_acc:\n",
    "        temp_max = test_acc\n",
    "        max_index = index\n",
    "    index += 1\n",
    "\n",
    "print(opt_name[max_index] + \" with an accuracy of:\",temp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt_name[max_index],\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=1)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = pd.read_csv('mock_data_key.csv')\n",
    "\n",
    "print(data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df_mock, feature, category,index):\n",
    "    cat = ''\n",
    "    if category == 0:\n",
    "        cat = 'MALNOURISHED'\n",
    "    elif category == 1:\n",
    "        cat = 'NORMAL/DESIRABLE'\n",
    "    elif category == 2:\n",
    "        cat = 'BORDERLINE RISK'\n",
    "    elif category == 3:\n",
    "        cat = 'OVERWEIGHT/AT RISK'\n",
    "    elif category == 4:\n",
    "        cat = 'HIGH RISK'\n",
    "    else:\n",
    "        prin(\"Error\")\n",
    "    \"\"\"\n",
    "    m_data.iloc[i][p] = data\n",
    "    \"\"\"\n",
    "    data = data_key.loc[feature,cat]\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('mock_data.csv')\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Category')\n",
    "\n",
    "y = df['Category']\n",
    "c = [p for p in range(len(y))]\n",
    "    \n",
    "m_data = pd.DataFrame(np.zeros((len(y),len(properties))),columns=properties,index=c)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    for p in properties:\n",
    "        data = df.iloc[i][p]\n",
    "        if type(data) == str:\n",
    "            print(\"We got a string, should not happen\")\n",
    "            data = np.float64(data.replace(',',''))\n",
    "            if np.isnan(data):\n",
    "                #outcome = df.iloc[i]['Category']\n",
    "                cleanData(m_data,p,outcome,i)\n",
    "            else:\n",
    "                m_data.iloc[i][p] = data\n",
    "                print(\"-Added to m_data\")\n",
    "        elif np.isnan(data):\n",
    "            #outcome = df.iloc[i]['Category']\n",
    "            pass\n",
    "        else:\n",
    "            m_data.iloc[i][p] = data\n",
    "\n",
    "X = m_data[properties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "y_train = keras.utils.to_categorical(y_train) #turning targets into categorical vectors training\n",
    "y_test = keras.utils.to_categorical(y_test) #turning targets into categorical vectors testing\n",
    "num_classes = len(y_test[0])\n",
    "\n",
    "feature_vector_length = len(properties)\n",
    "input_shape = (feature_vector_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "c_model = keras.Sequential()\n",
    "c_model.add(keras.layers.Dense(32,input_shape=input_shape,activation=tf.nn.relu,kernel_initializer='he_uniform'))\n",
    "c_model.add(keras.layers.Dense(32,activation=tf.nn.relu,kernel_initializer='he_uniform'))\n",
    "c_model.add(keras.layers.Dense(num_classes,activation=tf.nn.softmax))\n",
    "\n",
    "c_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#history = c_model.fit(X_train,y_train,epochs=64,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 887.8083 - accuracy: 0.1667\n",
      "Test results - Loss: 887.8082885742188 - Accuracy: 16.66666716337204%\n"
     ]
    }
   ],
   "source": [
    "test_results = c_model.evaluate(X_test,y_test,verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
    "\n",
    "# Save the model if it is 100% accurate\n",
    "if test_results[1]*100 == 100:\n",
    "    c_model.save('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True= Malnourished\n",
      "Pred= High Risk\n",
      "True= Normal\n",
      "Pred= High Risk\n",
      "True= Borderline Risk\n",
      "Pred= High Risk\n",
      "True= Overweight At Risk\n",
      "Pred= High Risk\n",
      "True= High Risk\n",
      "Pred= High Risk\n"
     ]
    }
   ],
   "source": [
    "test_01 = [24,63,81,65,69,76,75,169,0,109,86,4.2,0.53,102,3,2.5,2.5,2,1.5,1800,52,34,19,55,12,999,124,2,415]\n",
    "test_02 = [28,85,84,130,84,57,100,192,0.21,200,111,6.3,1.8,90,7,0,0,0,0,2300,59,40,39,0,0,0,0,0,0]\n",
    "test_03 = [30,92,91,165,99,42,158,208,0.25,398,124,6.5,2.8,89,9,0,0,7,0,2600,62,40,40,0,0,0,0,0,0]\n",
    "test_04 = [45,106,105,182,130,31,176,256,0.38,520,130,9.5,3.8,80,12,0,0,9,0,3400,69,48,51,101,24,3025,147,3.4,640]\n",
    "test_00 = [17,50,70,55,66,27,55,100,0,0,48,3.8,0,84,2,0,0,1,0,1799,40,20,15,25,10,699,75,1.4,390]\n",
    "t = [test_00,test_01,test_02,test_03,test_04]\n",
    "res = c_model.predict(t)\n",
    "\n",
    "for i,rr in enumerate(res):\n",
    "    max_i = 0\n",
    "    max_r = 0\n",
    "    if i == 0:\n",
    "        print(\"True= Malnourished\")\n",
    "    elif i == 1:\n",
    "        print(\"True= Normal\")\n",
    "    elif i == 2:\n",
    "        print(\"True= Borderline Risk\")\n",
    "    elif i == 3:\n",
    "        print(\"True= Overweight At Risk\")\n",
    "    elif i == 4:\n",
    "        print(\"True= High Risk\")\n",
    "    for ri,r in enumerate(rr):\n",
    "        if r > max_r:\n",
    "            max_i = ri\n",
    "            max_r = r\n",
    "    if max_i == 0:\n",
    "        print(\"Pred= Malnourished\")\n",
    "    elif max_i == 1:\n",
    "        print(\"Pred= Normal\")\n",
    "    elif max_i == 2:\n",
    "        print(\"Pred= Borderline Risk\")\n",
    "    elif max_i == 3:\n",
    "        print(\"Pred= Overweight At Risk\")\n",
    "    elif max_i == 4:\n",
    "        print(\"Pred= High Risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Still need more data for this to be more accurate, highest accuracy is 100% #### \n",
    "QUESTIONALBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x1426a4280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0421 - accuracy: 1.0000\n",
      "Test results - Loss: 0.04211745783686638 - Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# load a saved model\n",
    "cat_model = keras.models.load_model('models')\n",
    "test_results = cat_model.evaluate(X_test,y_test,verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True= Malnourished\n",
      "Pred= Malnourished\n",
      "True= Normal\n",
      "Pred= Normal\n",
      "True= Borderline Risk\n",
      "Pred= Borderline Risk\n",
      "True= Overweight At Risk\n",
      "Pred= Overweight At Risk\n",
      "True= High Risk\n",
      "Pred= High Risk\n"
     ]
    }
   ],
   "source": [
    "res = cat_model.predict(t)\n",
    "\n",
    "for i,rr in enumerate(res):\n",
    "    max_i = 0\n",
    "    max_r = 0\n",
    "    if i == 0:\n",
    "        print(\"True= Malnourished\")\n",
    "    elif i == 1:\n",
    "        print(\"True= Normal\")\n",
    "    elif i == 2:\n",
    "        print(\"True= Borderline Risk\")\n",
    "    elif i == 3:\n",
    "        print(\"True= Overweight At Risk\")\n",
    "    elif i == 4:\n",
    "        print(\"True= High Risk\")\n",
    "    for ri,r in enumerate(rr):\n",
    "        if r > max_r:\n",
    "            max_i = ri\n",
    "            max_r = r\n",
    "    if max_i == 0:\n",
    "        print(\"Pred= Malnourished\")\n",
    "    elif max_i == 1:\n",
    "        print(\"Pred= Normal\")\n",
    "    elif max_i == 2:\n",
    "        print(\"Pred= Borderline Risk\")\n",
    "    elif max_i == 3:\n",
    "        print(\"Pred= Overweight At Risk\")\n",
    "    elif max_i == 4:\n",
    "        print(\"Pred= High Risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Food DB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  fdc_id  seq_num  food_attribute_type_id      name  \\\n",
      "0     5578  323121      0.0                    1000       NaN   \n",
      "1     5579  327046      0.0                    1000       NaN   \n",
      "2     5580  333476      0.0                    1000       NaN   \n",
      "3     5581  334247      0.0                    1000       NaN   \n",
      "4     5582  334849      0.0                    1000       NaN   \n",
      "...    ...     ...      ...                     ...       ...   \n",
      "2440  8009  336065      0.0                     999  Genotype   \n",
      "2441  8010  336065      0.0                     999   Barcode   \n",
      "2442  8011  336066      0.0                     999       DOI   \n",
      "2443  8012  336066      0.0                     999  Genotype   \n",
      "2444  8013  336066      0.0                     999   Barcode   \n",
      "\n",
      "                                                  value  \n",
      "0                                hot dog, frank, wiener  \n",
      "1                                    Chinese gooseberry  \n",
      "2                                               Pollock  \n",
      "3                                               sucrose  \n",
      "4     URMIS # 2219, Kansas City Strip, Boneless Stri...  \n",
      "...                                                 ...  \n",
      "2440                                              Orion  \n",
      "2441                                         11G5060386  \n",
      "2442                        10.2135/cropsci2017.04.0244  \n",
      "2443                                              Orion  \n",
      "2444                                         11G5060694  \n",
      "\n",
      "[2445 rows x 6 columns]\n",
      "       fdc_id           data_type             description  food_category_id  \\\n",
      "0      319875  market_acquisition   HUMMUS, SABRA CLASSIC              16.0   \n",
      "1      319876  market_acquisition   HUMMUS, SABRA CLASSIC              16.0   \n",
      "2      319880  market_acquisition   HUMMUS, SABRA CLASSIC              16.0   \n",
      "3      319881  market_acquisition   HUMMUS, SABRA CLASSIC              16.0   \n",
      "4      319886  market_acquisition   HUMMUS, SABRA CLASSIC              16.0   \n",
      "...       ...                 ...                     ...               ...   \n",
      "19239  790901         sample_food  BANANAS, SLIGHTLY RIPE               9.0   \n",
      "19240  790919         sample_food  BANANAS, SLIGHTLY RIPE               9.0   \n",
      "19241  790937         sample_food           BANANAS, RIPE               9.0   \n",
      "19242  790955         sample_food  BANANAS, SLIGHTLY RIPE               9.0   \n",
      "19243  790973         sample_food           BANANAS, RIPE               9.0   \n",
      "\n",
      "      publication_date  \n",
      "0           2019-04-01  \n",
      "1           2019-04-01  \n",
      "2           2019-04-01  \n",
      "3           2019-04-01  \n",
      "4           2019-04-01  \n",
      "...                ...  \n",
      "19239       2020-04-01  \n",
      "19240       2020-04-01  \n",
      "19241       2020-04-01  \n",
      "19242       2020-04-01  \n",
      "19243       2020-04-01  \n",
      "\n",
      "[19244 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "food_attr = pd.read_csv('food_attribute.csv')\n",
    "\n",
    "print(food_attr)\n",
    "\n",
    "food = pd.read_csv('food.csv')\n",
    "print(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
