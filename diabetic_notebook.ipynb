{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Outcome')\n",
    "X = df[properties]\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(input_shape=(8,)),\n",
    "                            keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "                            keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "                            keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 9.6836 - accuracy: 0.4601\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 1.1313 - accuracy: 0.5322\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.8363 - accuracy: 0.6181\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.8003 - accuracy: 0.6135\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.7266 - accuracy: 0.6334\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.6334\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6957 - accuracy: 0.6350\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6671 - accuracy: 0.6687\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.6575 - accuracy: 0.6718\n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6564\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.6556 - accuracy: 0.6472\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6672: 0s - l - ETA: 0s - loss: 0.6455 - accuracy: 0.66\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6392 - accuracy: 0.6733\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.6192 - accuracy: 0.6718\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.6391 - accuracy: 0.6687: 0s - loss: 0.6395 - accuracy: 0.66\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.6341 - accuracy: 0.6656TA: 0s - loss: 0.5968 \n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.6098 - accuracy: 0.6794\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.6212 - accuracy: 0.6672\n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5847 - accuracy: 0.6856\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5868 - accuracy: 0.6933\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 3s 4ms/step - loss: 0.5832 - accuracy: 0.6979: 0s - loss: 0.5893 - ac - ETA: 0s - l\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6794\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.5765 - accuracy: 0.6856\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7163\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.5668 - accuracy: 0.7239\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7500\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5591 - accuracy: 0.7117\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5586 - accuracy: 0.7117\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7147\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5576 - accuracy: 0.7163\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.5572 - accuracy: 0.7178\n",
      "Epoch 6/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7163\n",
      "Epoch 7/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5564 - accuracy: 0.7147\n",
      "Epoch 8/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5560 - accuracy: 0.7132\n",
      "Epoch 9/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5556 - accuracy: 0.7147: 0s - loss: 0.5606 - accuracy: \n",
      "Epoch 10/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5553 - accuracy: 0.7163\n",
      "Epoch 11/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7147: 0s - loss: 0.609 - ETA: 0s - loss: 0.5600 - accuracy - ETA: 0s - loss: 0.5505 - accuracy: 0.\n",
      "Epoch 12/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7147\n",
      "Epoch 13/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5543 - accuracy: 0.7147\n",
      "Epoch 14/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5540 - accuracy: 0.7101\n",
      "Epoch 15/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5538 - accuracy: 0.7101\n",
      "Epoch 16/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5535 - accuracy: 0.7101\n",
      "Epoch 17/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7101\n",
      "Epoch 18/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7086: 0s - loss: 0.5499 - accuracy: \n",
      "Epoch 19/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7101: 0s - loss: 0.5599 - ac\n",
      "Epoch 20/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7071\n",
      "Epoch 21/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7071: 0s - loss: 0.538\n",
      "Epoch 22/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7071\n",
      "Epoch 23/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7071\n",
      "Epoch 24/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5517 - accuracy: 0.7071\n",
      "Epoch 25/25\n",
      "652/652 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.7071\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7500\n",
      "Epoch 1/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5492 - accuracy: 0.7117\n",
      "Epoch 2/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5401 - accuracy: 0.7071\n",
      "Epoch 3/25\n",
      "652/652 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7086\n",
      "Epoch 4/25\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7163\n",
      "Epoch 5/25\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.5342 - accuracy: 0.7239: 0s - loss: 0.5376 - accuracy: 0.71\n",
      "Epoch 6/25\n",
      "331/652 [==============>...............] - ETA: 1s - loss: 0.5158 - accuracy: 0.7492"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "release unlocked lock",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_acquire_restore\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# Ignore saved state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c55131925fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: release unlocked lock"
     ]
    }
   ],
   "source": [
    "opt_name = [\"nadam\", \"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"ftrl\"]\n",
    "model_acc = []\n",
    "temp_max = 0\n",
    "max_index = 0\n",
    "index = 0\n",
    "for name in opt_name:\n",
    "    model.compile(optimizer=name,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=25, batch_size=1)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    if temp_max < test_acc:\n",
    "        temp_max = test_acc\n",
    "        max_index = index\n",
    "    index += 1\n",
    "\n",
    "print(opt_name[max_index] + \" with an accuracy of:\",temp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt_name[max_index],\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=1)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            MALNOURISHED NORMAL/DESIRABLE BORDERLINE RISK  \\\n",
      "BMI                                 < 19            19-25           26-29   \n",
      "Weight (Kg)                         < 63            63-68           69-86   \n",
      "Waist Circumference (cm)            ≤ 73            74-81           82-89   \n",
      "Systolic BP (mmHg)                  ≤ 60           61-129         130-139   \n",
      "Diastolic BP (mmHg)                 ≤ 67            68-79           80-89   \n",
      "HDL-c (mg/dL)                       < 30           60-100           46-59   \n",
      "LDL-c (mg/dL)                       < 65            65-90          91-130   \n",
      "Total Cholesterol (mg/dL)          < 110          160-180         181-200   \n",
      "Atherogenicity index                   X         −0.3-0.1       0.11-0.24   \n",
      "TAG (mg/dL)                            X            < 150         150-200   \n",
      "FPG (mg/dL)                         < 75           75-100         100-115   \n",
      "HbA1c (%)                            < 4            4-5.7         5.7-6.4   \n",
      "CRP (mg/L)                             X            < 1.0         1.0-2.0   \n",
      "Pulse Oximetry (%)                  < 85             ≥ 95           90-94   \n",
      "Servings Grain (oz.)               < 3.0              3-7             7-8   \n",
      "Servings Fruit (2c.)                 0-1              2-3               X   \n",
      "Servings Veg (2.5c.)                 0-1              2-3               X   \n",
      "Servings Pro (5.5oz.)              < 1.0              2-6               X   \n",
      "Servings Dairy (1c.)                   X              0-4               X   \n",
      "Total Caloric Intake (kcal)       < 1800        1800-2200       2200-2400   \n",
      "% Energy CHO                        < 40            40-55           55-60   \n",
      "% Energy Pro                        < 20            20-35           35-40   \n",
      "% Energy Fat                        < 15            15-25           30-40   \n",
      "Vitamin D (mcg)                     < 25           25-100               X   \n",
      "Vitamin E (mg)                      ≤ 11            12-18               X   \n",
      "Vitamin A (mcg)                    ≤ 699         700-1000               X   \n",
      "Vitamin K (mcg)                    ≤ 109          110-140               X   \n",
      "Vitamin B12 (mcg)                  ≤ 1.4          1.5-3.0               X   \n",
      "Folate (mcg)                       ≤ 399          400-600               X   \n",
      "\n",
      "                            OVERWEIGHT/AT RISK HIGH RISK  \n",
      "BMI                                      30-39      ≥ 40  \n",
      "Weight (Kg)                              87-97      ≥ 98  \n",
      "Waist Circumference (cm)                89-102     ≥ 103  \n",
      "Systolic BP (mmHg)                     140-180     ≥ 181  \n",
      "Diastolic BP (mmHg)                     90-120     ≥ 121  \n",
      "HDL-c (mg/dL)                            35-45      ≤ 40  \n",
      "LDL-c (mg/dL)                          130-159     > 160  \n",
      "Total Cholesterol (mg/dL)              200-239     ≥ 240  \n",
      "Atherogenicity index                   .25-0.3     > 0.3  \n",
      "TAG (mg/dL)                            200-499     ≥ 500  \n",
      "FPG (mg/dL)                            115-125     > 125  \n",
      "HbA1c (%)                              6.5-8.0     ≥ 8.0  \n",
      "CRP (mg/L)                             2.0-3.0     > 3.0  \n",
      "Pulse Oximetry (%)                       85-90      < 85  \n",
      "Servings Grain (oz.)                      9-10      > 10  \n",
      "Servings Fruit (2c.)                         X         X  \n",
      "Servings Veg (2.5c.)                         X         X  \n",
      "Servings Pro (5.5oz.)                      6-7       > 8  \n",
      "Servings Dairy (1c.)                         X         X  \n",
      "Total Caloric Intake (kcal)          2400-3000    > 3000  \n",
      "% Energy CHO                             60-65      > 65  \n",
      "% Energy Pro                             40-45      > 45  \n",
      "% Energy Fat                             40-45      > 45  \n",
      "Vitamin D (mcg)                              X     > 100  \n",
      "Vitamin E (mg)                               X      > 18  \n",
      "Vitamin A (mcg)                              X    > 3000  \n",
      "Vitamin K (mcg)                              X     > 140  \n",
      "Vitamin B12 (mcg)                            X     > 3.0  \n",
      "Folate (mcg)                                 X     > 600  \n"
     ]
    }
   ],
   "source": [
    "data_key = pd.read_csv('mock_data_key.csv')\n",
    "\n",
    "print(data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df_mock, feature, category,index):\n",
    "    cat = ''\n",
    "    if category == 0:\n",
    "        cat = 'MALNOURISHED'\n",
    "    elif category == 1:\n",
    "        cat = 'NORMAL/DESIRABLE'\n",
    "    elif category == 2:\n",
    "        cat = 'BORDERLINE RISK'\n",
    "    elif category == 3:\n",
    "        cat = 'OVERWEIGHT/AT RISK'\n",
    "    elif category == 4:\n",
    "        cat = 'HIGH RISK'\n",
    "    else:\n",
    "        prin(\"Error\")\n",
    "    \"\"\"\n",
    "    m_data.iloc[i][p] = data\n",
    "    \"\"\"\n",
    "    data = data_key.loc[feature,cat]\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BMI  Weight (Kg)  Waist Circumfrence (cm)  Systolic BP (mmHg)  \\\n",
      "0    17.0         50.0                     70.0                55.0   \n",
      "1    18.0         54.0                     73.0                60.0   \n",
      "2    16.0         56.0                     72.0                59.0   \n",
      "3    17.0         57.0                     71.0                57.0   \n",
      "4    18.0         53.0                     70.0                59.0   \n",
      "..    ...          ...                      ...                 ...   \n",
      "114  50.0        106.0                    105.0               182.0   \n",
      "115  47.0        119.0                    106.0               181.0   \n",
      "116  45.0        107.0                    107.0              1184.0   \n",
      "117  47.0        118.0                    109.0               185.0   \n",
      "118  50.0        120.0                    110.0               184.0   \n",
      "\n",
      "     Diastolic BP (mmHg)  HDL-c (mg/dl)  LDL-c (mg/dl)  \\\n",
      "0                   66.0           27.0           55.0   \n",
      "1                   67.0           28.0           50.0   \n",
      "2                   64.0           29.0           62.0   \n",
      "3                   66.0           30.0           61.0   \n",
      "4                   65.0           23.0           60.0   \n",
      "..                   ...            ...            ...   \n",
      "114                122.0           35.0          162.0   \n",
      "115                128.0           40.0          161.0   \n",
      "116                135.0           33.0          164.0   \n",
      "117                130.0           32.0          175.0   \n",
      "118                121.0           31.0          190.0   \n",
      "\n",
      "     Total Cholesterol (mg/dL)  Atherogenicity index  TAG (mg/dL)  ...  \\\n",
      "0                        100.0                  0.00          0.0  ...   \n",
      "1                        102.0                  0.00          0.0  ...   \n",
      "2                        104.0                  0.00          0.0  ...   \n",
      "3                        105.0                  0.00          0.0  ...   \n",
      "4                        107.0                  0.00          0.0  ...   \n",
      "..                         ...                   ...          ...  ...   \n",
      "114                      265.0                  0.37        503.0  ...   \n",
      "115                      270.0                  0.35        505.0  ...   \n",
      "116                      250.0                  0.35        530.0  ...   \n",
      "117                      245.0                  0.37        540.0  ...   \n",
      "118                      260.0                  0.39        500.0  ...   \n",
      "\n",
      "     Total Caloric Intake (kcal)  % Energy CHO  % Energy Pro  % Energy Fat  \\\n",
      "0                         1799.0          40.0          20.0          15.0   \n",
      "1                         1798.0          39.0          14.0          14.0   \n",
      "2                         1750.0          38.0          15.0          13.0   \n",
      "3                         1700.0          37.0          17.0          12.0   \n",
      "4                         1600.0          36.0          18.0          14.0   \n",
      "..                           ...           ...           ...           ...   \n",
      "114                       3001.0          68.0          48.0          55.0   \n",
      "115                       3800.0          72.0          55.0          52.0   \n",
      "116                       3700.0          73.0          53.0          54.0   \n",
      "117                       3005.0          74.0          50.0          48.0   \n",
      "118                       4000.0          75.0          51.0          55.0   \n",
      "\n",
      "     Vitamin D (mcg)  Vitamin E (mg)  Vitamin A (mcg)  Vitamin K (mcg)  \\\n",
      "0               25.0            10.0            699.0             75.0   \n",
      "1               20.0            11.0            698.0             92.0   \n",
      "2               21.0            11.0            697.0             88.0   \n",
      "3               23.0            10.0            650.0             91.0   \n",
      "4               24.0             9.0            660.0             93.0   \n",
      "..               ...             ...              ...              ...   \n",
      "114            110.0            23.0           3060.0            145.0   \n",
      "115            111.0            22.0           3100.0            146.0   \n",
      "116            107.0            20.0           3050.0            147.0   \n",
      "117            105.0            19.0           3070.0            148.0   \n",
      "118            103.0            18.0           3090.0            155.0   \n",
      "\n",
      "     Vitamin B12 (mcg)  Folate (mcg)  \n",
      "0                  1.4         390.0  \n",
      "1                  1.3         380.0  \n",
      "2                  1.0         397.0  \n",
      "3                  1.1         364.0  \n",
      "4                  0.8         376.0  \n",
      "..                 ...           ...  \n",
      "114                3.6         645.0  \n",
      "115                3.5         620.0  \n",
      "116                3.6         610.0  \n",
      "117                3.7         650.0  \n",
      "118                4.0         605.0  \n",
      "\n",
      "[119 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('mock_data.csv')\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Category')\n",
    "\n",
    "y = df['Category']\n",
    "c = [p for p in range(len(y))]\n",
    "    \n",
    "m_data = pd.DataFrame(np.zeros((len(y),len(properties))),columns=properties,index=c)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    for p in properties:\n",
    "        data = df.iloc[i][p]\n",
    "        if type(data) == str:\n",
    "            print(\"We got a string, should not happen\")\n",
    "            data = np.float64(data.replace(',',''))\n",
    "            if np.isnan(data):\n",
    "                #outcome = df.iloc[i]['Category']\n",
    "                cleanData(m_data,p,outcome,i)\n",
    "            else:\n",
    "                m_data.iloc[i][p] = data\n",
    "                print(\"-Added to m_data\")\n",
    "        elif np.isnan(data):\n",
    "            #outcome = df.iloc[i]['Category']\n",
    "            pass\n",
    "        else:\n",
    "            m_data.iloc[i][p] = data\n",
    "\n",
    "X = m_data[properties]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "y_train = keras.utils.to_categorical(y_train) #turning targets into categorical vectors training\n",
    "y_test = keras.utils.to_categorical(y_test) #turning targets into categorical vectors testing\n",
    "num_classes = len(y_test[0])\n",
    "\n",
    "feature_vector_length = len(properties)\n",
    "input_shape = (feature_vector_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1546.0370 - accuracy: 0.1176 - val_loss: 1590.8621 - val_accuracy: 0.0909\n",
      "Epoch 2/64\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1340.1609 - accuracy: 0.1176 - val_loss: 1370.7899 - val_accuracy: 0.0909\n",
      "Epoch 3/64\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1137.6271 - accuracy: 0.1176 - val_loss: 1157.8032 - val_accuracy: 0.0909\n",
      "Epoch 4/64\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 943.7011 - accuracy: 0.1294 - val_loss: 998.0344 - val_accuracy: 0.1818\n",
      "Epoch 5/64\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 826.0406 - accuracy: 0.1765 - val_loss: 902.8140 - val_accuracy: 0.1364\n",
      "Epoch 6/64\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 732.0406 - accuracy: 0.2471 - val_loss: 785.5867 - val_accuracy: 0.1364\n",
      "Epoch 7/64\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 640.1606 - accuracy: 0.2588 - val_loss: 654.6033 - val_accuracy: 0.1364\n",
      "Epoch 8/64\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 533.9482 - accuracy: 0.2235 - val_loss: 523.2062 - val_accuracy: 0.1364\n",
      "Epoch 9/64\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 417.5891 - accuracy: 0.1882 - val_loss: 402.4821 - val_accuracy: 0.1818\n",
      "Epoch 10/64\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 326.4823 - accuracy: 0.1882 - val_loss: 288.8143 - val_accuracy: 0.1818\n",
      "Epoch 11/64\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 235.3864 - accuracy: 0.1882 - val_loss: 175.6248 - val_accuracy: 0.1818\n",
      "Epoch 12/64\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 141.3260 - accuracy: 0.1647 - val_loss: 71.1585 - val_accuracy: 0.3636\n",
      "Epoch 13/64\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 61.4570 - accuracy: 0.3059 - val_loss: 26.5118 - val_accuracy: 0.5455\n",
      "Epoch 14/64\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 25.5714 - accuracy: 0.4353 - val_loss: 19.0628 - val_accuracy: 0.5909\n",
      "Epoch 15/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 14.6529 - accuracy: 0.6000 - val_loss: 9.2004 - val_accuracy: 0.6364\n",
      "Epoch 16/64\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 8.0068 - accuracy: 0.7059 - val_loss: 7.5350 - val_accuracy: 0.7273\n",
      "Epoch 17/64\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.9654 - accuracy: 0.6471 - val_loss: 12.7502 - val_accuracy: 0.7273\n",
      "Epoch 18/64\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 12.0782 - accuracy: 0.6118 - val_loss: 13.0311 - val_accuracy: 0.7273\n",
      "Epoch 19/64\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 12.0554 - accuracy: 0.6000 - val_loss: 9.8404 - val_accuracy: 0.7273\n",
      "Epoch 20/64\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.1192 - accuracy: 0.5647 - val_loss: 5.9971 - val_accuracy: 0.7727\n",
      "Epoch 21/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 6.5226 - accuracy: 0.5765 - val_loss: 6.1483 - val_accuracy: 0.7727\n",
      "Epoch 22/64\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 6.3121 - accuracy: 0.6353 - val_loss: 5.8366 - val_accuracy: 0.7273\n",
      "Epoch 23/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 5.8974 - accuracy: 0.6353 - val_loss: 3.9027 - val_accuracy: 0.7727\n",
      "Epoch 24/64\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.2530 - accuracy: 0.6353 - val_loss: 3.1486 - val_accuracy: 0.7273\n",
      "Epoch 25/64\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 4.8761 - accuracy: 0.6235 - val_loss: 3.0722 - val_accuracy: 0.7273\n",
      "Epoch 26/64\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 4.5343 - accuracy: 0.6471 - val_loss: 2.9461 - val_accuracy: 0.7273\n",
      "Epoch 27/64\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 4.2139 - accuracy: 0.6706 - val_loss: 2.3681 - val_accuracy: 0.7727\n",
      "Epoch 28/64\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8909 - accuracy: 0.6706 - val_loss: 2.0519 - val_accuracy: 0.7727\n",
      "Epoch 29/64\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.6266 - accuracy: 0.6588 - val_loss: 1.9916 - val_accuracy: 0.7727\n",
      "Epoch 30/64\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.6416 - accuracy: 0.6824 - val_loss: 2.0520 - val_accuracy: 0.7727\n",
      "Epoch 31/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.3243 - accuracy: 0.6941 - val_loss: 1.7205 - val_accuracy: 0.7727\n",
      "Epoch 32/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.2321 - accuracy: 0.6706 - val_loss: 1.6066 - val_accuracy: 0.8636\n",
      "Epoch 33/64\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 3.2252 - accuracy: 0.6941 - val_loss: 1.7847 - val_accuracy: 0.7727\n",
      "Epoch 34/64\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.1417 - accuracy: 0.6941 - val_loss: 2.1221 - val_accuracy: 0.7727\n",
      "Epoch 35/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.0051 - accuracy: 0.7059 - val_loss: 1.8160 - val_accuracy: 0.7727\n",
      "Epoch 36/64\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.0345 - accuracy: 0.6941 - val_loss: 1.8552 - val_accuracy: 0.7727\n",
      "Epoch 37/64\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.9161 - accuracy: 0.7294 - val_loss: 1.5663 - val_accuracy: 0.8182\n",
      "Epoch 38/64\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6269 - accuracy: 0.7176 - val_loss: 1.5469 - val_accuracy: 0.8182\n",
      "Epoch 39/64\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.4365 - accuracy: 0.7647 - val_loss: 1.5276 - val_accuracy: 0.8182\n",
      "Epoch 40/64\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.1025 - accuracy: 0.7882 - val_loss: 1.5433 - val_accuracy: 0.8182\n",
      "Epoch 41/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.0217 - accuracy: 0.7765 - val_loss: 1.5897 - val_accuracy: 0.7727\n",
      "Epoch 42/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9608 - accuracy: 0.7882 - val_loss: 1.6053 - val_accuracy: 0.7727\n",
      "Epoch 43/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.8199 - accuracy: 0.8353 - val_loss: 1.5075 - val_accuracy: 0.8636\n",
      "Epoch 44/64\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.8825 - accuracy: 0.8235 - val_loss: 1.7506 - val_accuracy: 0.8182\n",
      "Epoch 45/64\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.8258 - accuracy: 0.8471 - val_loss: 1.6612 - val_accuracy: 0.8182\n",
      "Epoch 46/64\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.8028 - accuracy: 0.8588 - val_loss: 1.5278 - val_accuracy: 0.8182\n",
      "Epoch 47/64\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7186 - accuracy: 0.8471 - val_loss: 1.6341 - val_accuracy: 0.7727\n",
      "Epoch 48/64\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.8380 - accuracy: 0.8471 - val_loss: 1.6543 - val_accuracy: 0.7727\n",
      "Epoch 49/64\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.0684 - accuracy: 0.8706 - val_loss: 2.2939 - val_accuracy: 0.8182\n",
      "Epoch 50/64\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.9421 - accuracy: 0.8824 - val_loss: 1.6201 - val_accuracy: 0.7727\n",
      "Epoch 51/64\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.6928 - accuracy: 0.8471 - val_loss: 1.6920 - val_accuracy: 0.7727\n",
      "Epoch 52/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.8212 - accuracy: 0.8824 - val_loss: 1.8244 - val_accuracy: 0.7727\n",
      "Epoch 53/64\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7604 - accuracy: 0.8706 - val_loss: 1.5510 - val_accuracy: 0.7727\n",
      "Epoch 54/64\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.7365 - accuracy: 0.8471 - val_loss: 1.5578 - val_accuracy: 0.7727\n",
      "Epoch 55/64\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.6230 - accuracy: 0.8471 - val_loss: 1.6070 - val_accuracy: 0.7727\n",
      "Epoch 56/64\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.7036 - accuracy: 0.8706 - val_loss: 1.6349 - val_accuracy: 0.7727\n",
      "Epoch 57/64\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6911 - accuracy: 0.8706 - val_loss: 1.5030 - val_accuracy: 0.7727\n",
      "Epoch 58/64\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.5180 - accuracy: 0.8588 - val_loss: 1.6105 - val_accuracy: 0.7727\n",
      "Epoch 59/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 35ms/step - loss: 1.7152 - accuracy: 0.8824 - val_loss: 1.7651 - val_accuracy: 0.7727\n",
      "Epoch 60/64\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.7623 - accuracy: 0.8824 - val_loss: 1.4322 - val_accuracy: 0.8182\n",
      "Epoch 61/64\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.7187 - accuracy: 0.8471 - val_loss: 1.6381 - val_accuracy: 0.8182\n",
      "Epoch 62/64\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7899 - accuracy: 0.8941 - val_loss: 1.4728 - val_accuracy: 0.7727\n",
      "Epoch 63/64\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.9990 - accuracy: 0.8588 - val_loss: 2.1101 - val_accuracy: 0.8182\n",
      "Epoch 64/64\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.8057 - accuracy: 0.8706 - val_loss: 1.4257 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "c_model = keras.Sequential()\n",
    "c_model.add(keras.layers.Dense(32,input_shape=input_shape,activation=tf.nn.relu,kernel_initializer='he_uniform'))\n",
    "c_model.add(keras.layers.Dense(32,activation=tf.nn.relu,kernel_initializer='he_uniform'))\n",
    "c_model.add(keras.layers.Dense(num_classes,activation=tf.nn.softmax))\n",
    "\n",
    "c_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = c_model.fit(X_train,y_train,epochs=64,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8897 - accuracy: 0.6667\n",
      "Test results - Loss: 1.8897490501403809 - Accuracy: 66.66666865348816%\n"
     ]
    }
   ],
   "source": [
    "test_results = c_model.evaluate(X_test,y_test,verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True= Malnourished\n",
      "Pred= Normal\n",
      "True= Normal\n",
      "Pred= Normal\n",
      "True= Borderline Risk\n",
      "Pred= Overweight At Risk\n",
      "True= Overweight At Risk\n",
      "Pred= Overweight At Risk\n",
      "True= High Risk\n",
      "Pred= High Risk\n"
     ]
    }
   ],
   "source": [
    "test_01 = [24,63,81,65,69,76,75,169,0,109,86,4.2,0.53,102,3,2.5,2.5,2,1.5,1800,52,34,19,55,12,999,124,2,415]\n",
    "test_02 = [28,85,84,130,84,57,100,192,0.21,200,111,6.3,1.8,90,7,0,0,0,0,2300,59,40,39,0,0,0,0,0,0]\n",
    "test_03 = [30,92,91,165,99,42,158,208,0.25,398,124,6.5,2.8,89,9,0,0,7,0,2600,62,40,40,0,0,0,0,0,0]\n",
    "test_04 = [45,106,105,182,130,31,176,256,0.38,520,130,9.5,3.8,80,12,0,0,9,0,3400,69,48,51,101,24,3025,147,3.4,640]\n",
    "test_00 = [17,50,70,55,66,27,55,100,0,0,48,3.8,0,84,2,0,0,1,0,1799,40,20,15,25,10,699,75,1.4,390]\n",
    "t = [test_00,test_01,test_02,test_03,test_04]\n",
    "res = c_model.predict(t)\n",
    "\n",
    "for i,rr in enumerate(res):\n",
    "    max_i = 0\n",
    "    max_r = 0\n",
    "    if i == 0:\n",
    "        print(\"True= Malnourished\")\n",
    "    elif i == 1:\n",
    "        print(\"True= Normal\")\n",
    "    elif i == 2:\n",
    "        print(\"True= Borderline Risk\")\n",
    "    elif i == 3:\n",
    "        print(\"True= Overweight At Risk\")\n",
    "    elif i == 4:\n",
    "        print(\"True= High Risk\")\n",
    "    for ri,r in enumerate(rr):\n",
    "        if r > max_r:\n",
    "            max_i = ri\n",
    "            max_r = r\n",
    "    if max_i == 0:\n",
    "        print(\"Pred= Malnourished\")\n",
    "    elif max_i == 1:\n",
    "        print(\"Pred= Normal\")\n",
    "    elif max_i == 2:\n",
    "        print(\"Pred= Borderline Risk\")\n",
    "    elif max_i == 3:\n",
    "        print(\"Pred= Overweight At Risk\")\n",
    "    elif max_i == 4:\n",
    "        print(\"Pred= High Risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Still need more data for this to be more accurate, highest accuracy is 66% ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
